{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying different methods of using LLM with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"Tell me the youngest driver.\",\"Tell me every driver who is German\",\"how many german drivers are?\", \"Tell me the oldest driver.\", \"which driver uses the number 14?\", \"which driver has the oldest birthdate?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "asdf = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='driverId: 1\\nname: hamilton\\nnumber: 44\\ncode: HAM\\nforename: Lewis\\nsurname: Hamilton\\ndate of birth: 1985-01-07\\nnationality: British', metadata={'source': 'drivers_full.csv', 'row': 0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'drivers_full.csv'\n",
    "loader = CSVLoader(file_path=file,encoding='utf-8')\n",
    "docs = loader.load()\n",
    "\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index_creator = VectorstoreIndexCreator()\n",
    "docsearch = index_creator.from_loaders([loader])\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Tell me the youngest driver.', 'result': ' The youngest driver is Pierre Gasly, with a date of birth of 1996-02-07.'}\n",
      "{'question': 'Tell me every driver that is German', 'result': ' Gerhard Mitter (driverId: 423), Hans Herrmann (driverId: 478), Kurt Kuhnke (driverId: 442), and Hans Klenk (driverId: 753) are all German.'}\n",
      "{'question': 'how many german drivers are?', 'result': ' Four.'}\n",
      "{'question': 'Tell me the oldest driver.', 'result': ' The oldest driver is Danny Kladis with a date of birth of 1917-02-10.'}\n",
      "{'question': 'which driver uses the number 14?', 'result': ' Fernando Alonso'}\n",
      "{'question': 'which driver has the oldest birthdate?', 'result': ' Bruce McLaren has the oldest birthdate, 1937-08-30.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "\n",
    "for query in queries:\n",
    "    chain = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=docsearch.vectorstore.as_retriever(), input_key=\"question\")\n",
    "    response = chain({\"question\": query})\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "responses = list(map(lambda query:index.query(query),queries))\n",
    "[display(Markdown(r)) for r in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    print(db.similarity_search(query))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == 'drivers.csv':\n",
    "    qdocs = \"\".join([docs[i].page_content for i in range(len(docs))])\n",
    "\n",
    "    for query in queries:\n",
    "        print(query)\n",
    "        response = llm.call_as_llm(f\"{qdocs} Question: {query}\") \n",
    "        display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    response = qa_stuff.run(query)\n",
    "    display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"map_reduce\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    response = qa_stuff.run(query)\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"refine\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    response = qa_stuff.run(query)\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type='map_rerank', \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "for query in queries:\n",
    "    print(query)\n",
    "    response = qa_stuff.run(query)\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding=embeddings,\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in queries:\n",
    "    print(query)\n",
    "    response = index.query(query, llm=llm)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
